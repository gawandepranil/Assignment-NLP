{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f21db1f0",
   "metadata": {},
   "source": [
    "## Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0705ffc",
   "metadata": {},
   "source": [
    "### Perform text cleaning, perform lemmatization (any method), remove stop words (any method), label encoding. Create representations using TF-IDF. Save outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b739820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e351b0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shubh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shubh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\shubh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2dd53ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   text     label\n",
      "0               I love machine learning  Positive\n",
      "1  Machine learning is very interesting  Positive\n",
      "2                I hate boring lectures  Negative\n",
      "3                This course is useless  Negative\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"text\": [\n",
    "        \"I love machine learning\",\n",
    "        \"Machine learning is very interesting\",\n",
    "        \"I hate boring lectures\",\n",
    "        \"This course is useless\"\n",
    "    ],\n",
    "    \"label\": [\"Positive\", \"Positive\", \"Negative\", \"Negative\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ce27902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                 i love machine learning\n",
      "1    machine learning is very interesting\n",
      "2                  i hate boring lectures\n",
      "3                  this course is useless\n",
      "Name: clean_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df[\"clean_text\"] = df[\"text\"].apply(clean_text)\n",
    "print(df[\"clean_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd359a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           love machine learning\n",
      "1    machine learning interesting\n",
      "2             hate boring lecture\n",
      "3                  course useless\n",
      "Name: processed_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "df[\"processed_text\"] = df[\"clean_text\"].apply(preprocess_text)\n",
    "print(df[\"processed_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff6ae8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label  label_encoded\n",
      "0  Positive              1\n",
      "1  Positive              1\n",
      "2  Negative              0\n",
      "3  Negative              0\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df[\"label_encoded\"] = label_encoder.fit_transform(df[\"label\"])\n",
    "\n",
    "print(df[[\"label\", \"label_encoded\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ecce246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    boring    course     hate  interesting  learning  lecture      love  \\\n",
      "0  0.00000  0.000000  0.00000     0.000000  0.526405  0.00000  0.667679   \n",
      "1  0.00000  0.000000  0.00000     0.667679  0.526405  0.00000  0.000000   \n",
      "2  0.57735  0.000000  0.57735     0.000000  0.000000  0.57735  0.000000   \n",
      "3  0.00000  0.707107  0.00000     0.000000  0.000000  0.00000  0.000000   \n",
      "\n",
      "    machine   useless  \n",
      "0  0.526405  0.000000  \n",
      "1  0.526405  0.000000  \n",
      "2  0.000000  0.000000  \n",
      "3  0.000000  0.707107  \n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df[\"processed_text\"])\n",
    "\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    columns=tfidf_vectorizer.get_feature_names_out()\n",
    ")\n",
    "\n",
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3de044aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_preprocessed_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1257c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df.to_csv(\"tfidf_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc7310e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = pd.DataFrame({\n",
    "    \"label\": label_encoder.classes_,\n",
    "    \"encoded_value\": range(len(label_encoder.classes_))\n",
    "})\n",
    "\n",
    "label_mapping.to_csv(\"label_mapping.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95b8b42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
